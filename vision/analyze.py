"""
Enhanced image analysis module using YOLO and SAM (OpenAI dependencies removed).
"""

import os
import logging
from typing import Dict, List, Any, Optional
from PIL import Image
import numpy as np

# Set up logging
logger = logging.getLogger(__name__)

class ImageAnalyzer:
    """
    Enhanced image analyzer using multiple AI models for comprehensive analysis.
    OpenAI CLIP and GPT-4V dependencies removed for compatibility.
    """
    
    def __init__(self):
        """Initialize the image analyzer with available models."""
        self.models_loaded = False
        self.yolo_model = None
        self.sam_model = None
        
        # Try to load models
        self._load_models()
    
    def _load_models(self):
        """Load all required models for analysis."""
        try:
            # Load YOLO model
            try:
                from ultralytics import YOLO
                self.yolo_model = YOLO('yolov8n.pt')
                logger.info("‚úÖ YOLO model loaded successfully")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not load YOLO model: {e}")
            
            # Load SAM model
            try:
                from segment_anything import sam_model_registry, SamPredictor
                sam_checkpoint = "sam_vit_h_4b8939.pth"  # This would need to be downloaded
                model_type = "vit_h"
                
                if os.path.exists(sam_checkpoint):
                    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
                    self.sam_predictor = SamPredictor(sam)
                    logger.info("‚úÖ SAM model loaded successfully")
                else:
                    logger.warning("‚ö†Ô∏è SAM checkpoint not found")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not load SAM model: {e}")
            
            self.models_loaded = True
            
        except Exception as e:
            logger.error(f"‚ùå Error loading models: {e}")
            self.models_loaded = False
    
    def analyze_comprehensive(self, image_path: str) -> Dict[str, Any]:
        """
        Perform comprehensive image analysis using available models.
        
        Args:
            image_path (str): Path to the image file
            
        Returns:
            Dict[str, Any]: Comprehensive analysis results
        """
        
        results = {
            "success": True,
            "image_path": image_path,
            "caption": "",
            "detailed_description": "",
            "yolo_detections": [],
            "sam_segments": [],
            "combined_analysis": ""
        }
        
        try:
            # Load image
            image = Image.open(image_path)
            
            # YOLO Object Detection
            if self.yolo_model is not None:
                results["yolo_detections"] = self._analyze_with_yolo(image_path)
                # Generate basic caption from YOLO detections
                if results["yolo_detections"]:
                    detected_objects = [det["class"] for det in results["yolo_detections"] if det["confidence"] > 0.5]
                    if detected_objects:
                        results["caption"] = f"Image containing: {', '.join(detected_objects[:3])}"
                    else:
                        results["caption"] = "Image with various objects detected"
                else:
                    results["caption"] = "Image analysis completed"
            
            # SAM Segmentation
            if hasattr(self, 'sam_predictor') and self.sam_predictor is not None:
                results["sam_segments"] = self._analyze_with_sam(image)
            
            # Combine all analyses
            results["combined_analysis"] = self._combine_analyses(results)
            results["detailed_description"] = results["combined_analysis"]
            
        except Exception as e:
            logger.error(f"‚ùå Error in comprehensive analysis: {e}")
            results["success"] = False
            results["error"] = str(e)
        
        return results
    
    def _analyze_with_yolo(self, image_path: str) -> List[Dict[str, Any]]:
        """Analyze image using YOLO object detection."""
        try:
            results = self.yolo_model(image_path)
            detections = []
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        detection = {
                            "class": result.names[int(box.cls)],
                            "confidence": float(box.conf),
                            "bbox": box.xyxy[0].tolist()
                        }
                        detections.append(detection)
            
            return detections
            
        except Exception as e:
            logger.error(f"‚ùå YOLO analysis error: {e}")
            return []
    
    def _analyze_with_sam(self, image: Image.Image) -> List[Dict[str, Any]]:
        """Analyze image using SAM segmentation."""
        try:
            # Convert PIL image to numpy array
            image_array = np.array(image)
            
            # Set image for SAM predictor
            self.sam_predictor.set_image(image_array)
            
            # Generate automatic masks
            # Note: This is a simplified version - full implementation would use SamAutomaticMaskGenerator
            segments = []
            
            # For demo purposes, return placeholder data
            segments.append({
                "area": image_array.shape[0] * image_array.shape[1],
                "bbox": [0, 0, image_array.shape[1], image_array.shape[0]],
                "predicted_iou": 0.9,
                "stability_score": 0.95
            })
            
            return segments
            
        except Exception as e:
            logger.error(f"‚ùå SAM analysis error: {e}")
            return []
    
    def _combine_analyses(self, results: Dict[str, Any]) -> str:
        """Combine all analysis results into a comprehensive description."""
        
        combined = "üîç **Comprehensive Image Analysis**\n\n"
        
        # YOLO Detections
        if results.get("yolo_detections"):
            combined += "**Object Detection (YOLO):**\n"
            for detection in results["yolo_detections"][:5]:  # Top 5 detections
                combined += f"- {detection['class']} (confidence: {detection['confidence']:.2f})\n"
            combined += "\n"
        
        # SAM Segmentation
        if results.get("sam_segments"):
            combined += f"**Segmentation Analysis (SAM):**\n"
            combined += f"- {len(results['sam_segments'])} segments detected\n"
            if results["sam_segments"]:
                avg_stability = sum(seg.get("stability_score", 0) for seg in results["sam_segments"]) / len(results["sam_segments"])
                combined += f"- Average stability score: {avg_stability:.2f}\n"
            combined += "\n"
        
        # Add fallback description if no models available
        if not results.get("yolo_detections") and not results.get("sam_segments"):
            combined += "**Basic Analysis:**\n"
            combined += "- Image loaded and processed successfully\n"
            combined += "- Advanced analysis models not available\n"
            combined += "- Consider using alternative image analysis tools\n\n"
        
        return combined
    
    def generate_video_prompt(self, analysis_result: Dict[str, Any]) -> str:
        """
        Generate a dynamic video prompt using WAN 2.1 format (Subject + Scene + Motion).
        
        Args:
            analysis_result (Dict[str, Any]): Results from analyze_comprehensive
            
        Returns:
            str: Generated video prompt in WAN 2.1 format
        """
        
        try:
            # Extract key information from analysis
            yolo_detections = analysis_result.get("yolo_detections", [])
            
            # Build WAN 2.1 format video prompt
            video_prompt = "üé¨ **WAN 2.1 Video Prompt**\n\n"
            
            # SUBJECT section
            video_prompt += "**SUBJECT**: "
            if yolo_detections:
                subjects = [det["class"] for det in yolo_detections if det["confidence"] > 0.5]
                if any("person" in str(subjects).lower()):
                    video_prompt += "Attractive person with natural pose and expression, detailed features"
                else:
                    video_prompt += f"Main elements: {', '.join(subjects[:2]) if subjects else 'central subject'}"
            else:
                video_prompt += "Central subject with detailed appearance and positioning"
            video_prompt += "\n\n"
            
            # SCENE section
            video_prompt += "**SCENE**: "
            video_prompt += "Well-lit environment with atmospheric lighting, detailed background, professional setting"
            video_prompt += "\n\n"
            
            # MOTION section
            video_prompt += "**MOTION**: "
            motion_elements = []
            
            # Determine motion based on detected objects
            if any("person" in det["class"] for det in yolo_detections):
                motion_elements.extend(["gentle movement", "natural gestures", "subtle expressions"])
            
            if any(obj in str(yolo_detections).lower() for obj in ["hair", "clothing", "fabric"]):
                motion_elements.extend(["fabric flow", "hair movement"])
            
            motion_elements.extend(["smooth camera pan", "gradual zoom"])
            
            video_prompt += ", ".join(motion_elements[:4])
            video_prompt += "\n\n"
            
            # Technical recommendations
            video_prompt += "**Technical Recommendations:**\n"
            video_prompt += "üìπ **Recommended FPS**: 24-30 fps for smooth motion\n"
            video_prompt += "‚è±Ô∏è **Optimal Duration**: 3-5 seconds for best quality\n"
            video_prompt += "üéûÔ∏è **Frame Count**: 72-150 frames (24fps √ó 3-5 seconds)\n"
            video_prompt += "üéõÔ∏è **Motion Strength**: 0.8 for natural movement\n\n"
            
            video_prompt += "**Analysis Notes:**\n"
            video_prompt += "- WAN 2.1 format optimized for video generation\n"
            video_prompt += "- Subject + Scene + Motion structure applied\n"
            video_prompt += "- Technical parameters optimized for quality\n"
            
            return video_prompt
            
        except Exception as e:
            logger.error(f"‚ùå Error generating video prompt: {e}")
            return f"‚ùå Error generating video prompt: {str(e)}"
